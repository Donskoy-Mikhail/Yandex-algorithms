"""
89908925

-- ПРИНЦИП РАБОТЫ --
Основной принцип работы заключается в том что мы создаем
своеобразную базу данных как для документов так и для релевантности документов что
позволяет делать поиск в документах по запросу за константное время для 
поиска одного слова что ускоряет сам поиск

Гораздо удобнее и быстрее будет если мы создамим словарь, в котором мы будем
хранить документы, где ключем будет слово а значениями будут пары из документа
и количества раз сколько слово встретилось в документе. Такой способ позволяет 
про проходе по уникальным словам запроса быстро обнаруживать документ и сколько раз в
нем встретилось уникальное искомое слово 

Далее алгоритм проходится по всем запросам и для каждого уникального слова
ищет в словаре документов документ и число раз что встречается слово
далее идет обновление словаря релевантности документа для запроса

После того как прошла проверка всех слов в запросе
проводим сортировку пар (документ, релевантность) по релевантности
(количеству раз что встретились слова из запроса в документе)
и производим печать номера документов

 -- ДОКАЗАТЕЛЬСТВО КОРРЕКТНОСТИ --

Алгоритм работает корректно за счет того что мы гарантировано для каждого
слова из документов создаем пару сколько раз встретилось это слово в конкретном 
документе 
и 
за счет того что для каждого уникального слова из запроса проводим проверку
в ранее созданном словаре с документами и по результам проверки проводим запись в словарь
релевантности количество раз что встретилось искомое слово

Далее же простая сортировка по релевантности позволяет задать порядок печати документов

В принципе основным моментом что доказывает корректностть алгоритма является то что мы
создаем словарь именно для каждого слова из документов и далее проводим поиск именно для каждого
уникального слова из запроса, 
если нарушить одно из условий озвученных выше то алгоритм не будет работать корректно 

-- ВРЕМЕННАЯ СЛОЖНОСТЬ --

Построение словаря по документам:

Проход по всем документам: O(n)
Проход по всем словам в документах: O(k), где k - средняя длина документа
Добавление элементов в словарь: O(1) (в среднем)
Итоговая временная сложность этапа: O(n * k)

Обработка запросов:

Проход по всем запросам: O(m)
Обработка слов в запросе: O(p), где p - среднее количество слов в запросе
Обновление счетчика релевантности: O(1) (в среднем)
Сортировка результатов: O(n * log(n)) где n количество документов
Итоговая временная сложность этапа: O(m * p + n * log(n))


Суммарная сложность: O(nk + mp + n * log(n))

-- ПРОСТРАНСТВЕННАЯ СЛОЖНОСТЬ --

Для хранения словаря по документам:

O(n * d): n - количество уникальных слов в документа, d - количество  документов

Для хранения словаря релевантности

O(d): d - количество  документов

Итоговая пространственная сложность O(n * d + d) => O(n * d)
"""

from collections import Counter, defaultdict


def indexer(documents):
    index = defaultdict(list)

    for doc_id, doc in enumerate(documents):
        words = doc.split()
        word_counter = Counter(words)
        for word, freq in word_counter.items():
            index[word].append((doc_id, freq))
    return index


def search_system(documents, queries):

    index = indexer(documents)
    for query in queries:
        query_words = set(query.split())
        relevance = Counter()

        for word in query_words:
            if word in index:
                relevance.update({doc_id: freq for doc_id, freq in index[word]})

        sorted_relevance = sorted(relevance.items(), key=lambda x: (-x[1], x[0]))

        result = [str(doc_id + 1) for doc_id, _ in sorted_relevance[:5]]

        print(" ".join(result))


if __name__ == "__main__":

    n_d = int(input())
    doc = [input() for _ in range(n_d)]

    m_q = int(input())
    qr = [input() for _ in range(m_q)]

    search_system(doc, qr)
